{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import time\n",
    "from src.utils import get_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_url_form = 'http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code={}&type={}&onlyActualPointYn=N&order=newest&page={}' # idx, type, page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def num_of_comment_pages(idx, after=True):\n",
    "    url = comments_url_form.format(idx, 'after' if after else 'before', 1)\n",
    "    soup = get_soup(url)\n",
    "\n",
    "    try:\n",
    "        num_comments = int(soup.select('div[class=score_total] em')[1].text.replace(',',''))\n",
    "        return math.ceil(num_comments / 5)\n",
    "    except Exception as e:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def parse_a_page(soup, after_strf):\n",
    "    comments = []\n",
    "    for row in soup.select('div[class=score_result] li'):\n",
    "        try:\n",
    "            score = int(row.select('div[class=star_score] em')[0].text.strip())\n",
    "            text = row.select('div[class=score_reple] p')[0].text.strip()\n",
    "            user = row.select('a[onclick^=javascript]')[0].attrs.get('onclick', '').split('(')[1].split(',')[0]\n",
    "            nickname = row.select('a[onclick^=javascript]')[0].text.strip()\n",
    "            written_at = re.search(r\"\\d+\\.\\d+\\.\\d+ \\d+:\\d+\", row.text).group()\n",
    "            agree = int(row.select('span[class^=sympathy]')[0].text.strip())\n",
    "            disagree = int(row.select('span[class^=notSympathy]')[0].text)\n",
    "            comments.append(\n",
    "                {'type': after_strf,\n",
    "                 'score': score,\n",
    "                 'text': text,\n",
    "                 'user': user,\n",
    "                 'nickname': nickname,\n",
    "                 'written_at': written_at,\n",
    "                 'agree': agree,\n",
    "                 'disagree': disagree,\n",
    "                })\n",
    "        except:\n",
    "            continue\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _scrap_comments(idx, limit, after, sleep=0.05):\n",
    "    after_strf = 'after' if after else 'before'\n",
    "    max_page = num_of_comment_pages(idx, after)\n",
    "    if limit > 0:\n",
    "        max_page = min(limit, max_page)\n",
    "    if max_page <= 0:\n",
    "        return []\n",
    "\n",
    "    comments = []\n",
    "    for p in range(1, max_page + 1):\n",
    "        url = comments_url_form.format(idx, 'after' if after else 'before', p)\n",
    "        comments += parse_a_page(get_soup(url), after_strf)\n",
    "        if p % 20 == 0:\n",
    "            print('\\r  movie {}, {}, {} / {} ...'.format(idx, after_strf, p, max_page), end='')\n",
    "    print('\\r  movie {}, {}, {} / {} done'.format(idx, after_strf, p, max_page))\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def scrap_comments(idx, limit=-1, sleep=0.05):\n",
    "    comments = _scrap_comments(idx, limit, after=True, sleep=sleep)\n",
    "    comments += _scrap_comments(idx, limit, after=False, sleep=sleep)\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(idx, directory, casting=True, bestscripts=True, comments=True, limit=3, sleep=0.05):\n",
    "    # basic\n",
    "    save_json(scrap_basic(idx), '{}/meta/{}.json'.format(directory, idx))\n",
    "    print('scraped {} basic'.format(idx))\n",
    "\n",
    "    # castings\n",
    "    if casting:\n",
    "        castings = scrap_casting(idx)\n",
    "        for key in ['actors', 'directors', 'staffs']:\n",
    "            if castings.get(key, []):\n",
    "                save_list_of_dict(castings[key], '{}/{}/{}'.format(directory, key, idx))\n",
    "        print('scraped {} casting'.format(idx))\n",
    "\n",
    "    # best scripts\n",
    "    if bestscripts:\n",
    "        scripts = scrap_bestscripts(idx, limit, sleep)\n",
    "        if scripts:\n",
    "            save_list_of_dict(scripts, '{}/bestscripts/{}'.format(directory, idx))\n",
    "        print('scraped {} best scripts'.format(idx))\n",
    "\n",
    "    # comments\n",
    "    if comments:\n",
    "        comments_ = scrap_comments(idx, limit, sleep)\n",
    "        if comments_:\n",
    "            save_list_of_dict(comments_, '{}/comments/{}'.format(directory, idx))\n",
    "        print('scraped {} comments'.format(idx))\n",
    "\n",
    "    print('')\n",
    "    time.sleep(sleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = []\n",
    "for idx in idxs:\n",
    "    try:\n",
    "        scrap(idx, directory, casting, bestscripts, comments, limit, sleep)\n",
    "    except Exception as e:\n",
    "        print('movie id = {}'.format(idx))\n",
    "        print(e)\n",
    "        exceptions.append((idx, str(e)))\n",
    "    if exceptions:\n",
    "        print('Exist {} exceptions'.format(len(exceptions)))\n",
    "\n",
    "with open('./log', 'w', encoding='utf-8') as f:\n",
    "    if not exceptions:\n",
    "        f.write('Information of all movies were scraped successfully.\\n')\n",
    "    else:\n",
    "        f.write('Exist exceptions\\n\\n')\n",
    "        for idx, e in exceptions:\n",
    "            f.write('movie id = {}'.format(idx))\n",
    "            f.write('{}\\n'.format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workspace",
   "language": "python",
   "name": "workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
